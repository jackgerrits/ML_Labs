{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to do linear regression with scikit in Python. We will explore how to predict home prices using a variety of features, both numerical and categorical. Along the way, we will also learn about some other concepts such as correlation, mean squared error and R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Data exploration/preparation: Load and understand data**\n",
    "\n",
    "**(2) Linear Regression**\n",
    "       - with a single feature\n",
    "       - with multiple numerical features\n",
    "       - with numerical and categorical features \n",
    "\n",
    "**(3) Understanding goodness of fit metrics**\n",
    "\n",
    "**(4) Standardization**\n",
    "\n",
    "**(5) Caveats and more things you can explore on your own**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration: Load and understand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import necessary packages\n",
    "import pandas as pd # data handling/manipulation package\n",
    "import os\n",
    "import numpy as np # mathematical and array operations\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg # plotting\n",
    "import warnings # handle warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('king_county_home_prices.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread(\"HousingDatasetFeatures.PNG\")\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into train and test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intution for splitting data into train and test:\n",
    "\n",
    "When you want to measure how well you have learnt something, you want to do some practice problems or take a practice exam. That is exactly what is happening here. You are putting some questions away as practice questions for yourself and learning from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sqft_living'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train['sqft_living'], train['price'])\n",
    "# titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python package sklearn requires data to be in matrix format ie.e two dimesional array\n",
    "# so we will transform single feature using the reshape() function\n",
    "\n",
    "data_train = np.array(train['sqft_living']).reshape(-1, 1)\n",
    "target_train = np.array(train['price']).reshape(-1, 1)\n",
    "\n",
    "data_test = np.array(test['sqft_living']).reshape(-1, 1)\n",
    "target_test = np.array(test['price']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear regression, we want to fit a linear equation to our data. In the case where we have just one independent variable, we are trying to fit a line. \n",
    "\n",
    "The canonical equation of a line is Y = mX + c. So, two real values completely determine a line. The sole purpose of the training process is to figure out the best possible 'm'  and  'c'. The value for 'c' is non zero only if the line does not pass through the origin.\n",
    "\n",
    "In our problem, we are solving price ~ m * sqft_living + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model1=LinearRegression()\n",
    "model1.fit(data_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(data_test, target_test,  color='black')\n",
    "plt.plot(data_test, preds, color='blue', linewidth=3)\n",
    "plt.title('price ~ m * sqft_living + c')\n",
    "plt.xlabel('sqft_living')\n",
    "plt.ylabel('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of sqft_living or \\'m\\': ', model1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This coefficient tells us that for a unit increase in sqft_living, the price of a home increases by $279.62829594"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's think along these lines ...... see what I did there? :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fit a line, we want to know how good our line is i.e. we need some way to measure how well its predictions\n",
    "actually match the observed data. Below are a few metrics that are used to evaluate goodness of fit.\n",
    "\n",
    "(1) **Mean Square error/ squared loss**\n",
    "\n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^{N} (y_i - f(x_i))^2$$\n",
    "\n",
    "This is the most commonly used metric. However, the error does not have the same 'units' as the dependent variable i.e. price in our problem.\n",
    "\n",
    "(2) **Root Mean Squared Error**\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} (y_i - f(x_i))^2}$$\n",
    "\n",
    "(3) **R^2**\n",
    "\n",
    "This metric indicates the percentage of the variance in the value that we are trying to predict that the features explain collectively. \n",
    "\n",
    "$$ R^2 = \\frac{\\text{Variance explained by the model}}{\\text{Total variance}} = 1 - \\frac{\\text{variance unexplained by model}}{\\text{total variance}} = 1 - \\frac{\\text{MSE of model}}{\\text{MSE of baseline (always predicting the average outcome)}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding R^2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the average price gives us a notion of inherent variance in the data before regression was performed\n",
    "\n",
    "avg_price = np.mean(target_test)\n",
    "print(\"average price: \", '{:,.2f}'.format(avg_price))\n",
    "preds_avg_price = np.array([avg_price] * len(target_test)).reshape(-1, 1)\n",
    "\n",
    "# TSS : total sum of squares - total variance\n",
    "# RSS: residual sum of squares - variance UNEXPLAINED by the model\n",
    "\n",
    "MSE_baseline = np.mean((target_test - preds_avg_price)**2)\n",
    "MSE_model = np.mean((target_test - preds)**2)\n",
    "R_squared = 1 - MSE_model / MSE_baseline\n",
    "print(\"mean squared error of always predicting the average price: \", '{:,.2f}'.format(MSE_baseline))\n",
    "print(\"mean squared error for the model: \", '{:,.2f}'.format(MSE_model))\n",
    "print(\"R^2, or fraction of variance explained by model: %.2f\" % R_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Mean Squared Error: %.2f\" % mean_squared_error(target_test, preds))\n",
    "print(\"Root Mean Squared Error: %.2f\" % np.sqrt(mean_squared_error(target_test, preds)))\n",
    "print('R^2: %.2f' % r2_score(target_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with multiple numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "num_cols = ['bedrooms', 'bathrooms', 'sqft_living' , 'floors', 'sqft_above', 'sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = train[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"] \n",
    "fig_size[0]=16.0\n",
    "fig_size[1]=8.0\n",
    "df_sub.hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are a lot of homes without a basement, so let's transform that into a categorical variable. Let's deal with that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['bedrooms', 'bathrooms', 'sqft_living']\n",
    "\n",
    "#data prep\n",
    "data_train = np.array(train[num_cols])\n",
    "target_train = np.array(train['price'])\n",
    "\n",
    "data_test = np.array(test[num_cols])\n",
    "target_test = np.array(test['price'])\n",
    "\n",
    "# train the model\n",
    "model1=LinearRegression()\n",
    "model1.fit(data_train,target_train)\n",
    "\n",
    "# get predictions\n",
    "preds = model1.predict(data_test)\n",
    "\n",
    "# goodness of fit\n",
    "print(\"Mean Squared Error: %.2f\" % mean_squared_error(target_test, preds))\n",
    "print(\"Root Mean Squared Error: %.2f\" % np.sqrt(mean_squared_error(target_test, preds)))\n",
    "print('R^2: %.2f' % r2_score(target_test, preds))\n",
    "pd.DataFrame({'name':num_cols,'value':model1.coef_}).sort_values('value', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the coefficients, we learn that:\n",
    "\n",
    "- per unit increase in b,athrooms the price increases by \\$4.3k\n",
    "- per unit increase in number of times the home was viewed, the price increases by ~\\$300\n",
    "- however, notice that the number of bedrooms has a negative coefficient. This is clearly due to correlated features. After accounting for the variation explained by the other variables, the relationship between bedrooms and price is negative. Doing a multiple regression with predictors that are this highly correlated is likely to lead to flawed inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['bedrooms', 'bathrooms', 'sqft_living' , 'floors', 'sqft_above', 'sqft_basement']\n",
    "\n",
    "data_train = np.array(train[num_cols])\n",
    "target_train = np.array(train['price'])\n",
    "\n",
    "data_test = np.array(test[num_cols])\n",
    "target_test = np.array(test['price'])\n",
    "\n",
    "# train the model\n",
    "model1=LinearRegression()\n",
    "model1.fit(data_train,target_train)\n",
    "\n",
    "# get predictions\n",
    "preds = model1.predict(data_test)\n",
    "\n",
    "# goodness of fit\n",
    "print(\"Mean Squared Error: %.2f\" % mean_squared_error(target_test, preds))\n",
    "print(\"Root Mean Squared Error: %.2f\" % np.sqrt(mean_squared_error(target_test, preds)))\n",
    "print('R^2: %.2f' % r2_score(target_test, preds))\n",
    "pd.DataFrame({'name':num_cols,'value':model1.coef_}).sort_values('value', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data such as this, the weights are hard to interpret because of highly correlated features. The assumption that a unit increase in one keeping others constant is impossible to hold. How do you increase the number of floors by keeping sqft_living constant?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['bedrooms', 'sqft_living', 'view']\n",
    "\n",
    "data_train = np.array(train[num_cols])\n",
    "target_train = np.array(train['price'])\n",
    "\n",
    "data_test = np.array(test[num_cols])\n",
    "target_test = np.array(test['price'])\n",
    "\n",
    "# train the model\n",
    "model1=LinearRegression()\n",
    "model1.fit(data_train,target_train)\n",
    "\n",
    "# get predictions\n",
    "preds = model1.predict(data_test)\n",
    "\n",
    "# goodness of fit\n",
    "print(\"Mean Squared Error: %.2f\" % mean_squared_error(target_test, preds))\n",
    "print(\"Root Mean Squared Error: %.2f\" % np.sqrt(mean_squared_error(target_test, preds)))\n",
    "print('R^2: %.2f' % r2_score(target_test, preds))\n",
    "pd.DataFrame({'name':num_cols,'value':model1.coef_}).sort_values('value', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, we cannot order the features by their coefficients and infer feature importance because we have not standardized the data. \n",
    "\n",
    "Standardization is relevant when predictors i.e. independent variables are expressed in different units. Discerning importance of predictors based on the unstandardized coefficient would not be fair. This is because the units of these variable are not the same.\n",
    "\n",
    "- Unstandardized coefficients: It represents the amount by which dependent variable changes if we change independent variable by one unit keeping other independent variables constant.\n",
    "\n",
    "- Standardized coefficients: The standardized coefficient is measured in units of standard deviation. A coefficient value of 1.25 indicates that a change of one standard deviation in the independent variable results in a 1.25 standard deviations increase in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X_scaler = preprocessing.StandardScaler()\n",
    "data_train_std = X_scaler.fit_transform(data_train)\n",
    "data_test_std = X_scaler.transform(data_test)\n",
    "\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "target_train_std = y_scaler.fit_transform(target_train[:, None])[:, 0]\n",
    "target_test_std = y_scaler.transform(target_test[:, None])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=LinearRegression()\n",
    "model1.fit(data_train_std,target_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(data_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error: %.2f\" % mean_squared_error(target_test_std, preds))\n",
    "print(\"Root Mean Squared Error: %.2f\" % np.sqrt(mean_squared_error(target_test_std, preds)))\n",
    "print('R^2: %.2f' % r2_score(target_test_std, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'name':num_cols,'value':model1.coef_}).sort_values('value', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique values in zipcode: \", train['zipcode'].nunique())\n",
    "print(\"Number of unique values in yr_built: \", train['yr_built'].nunique())\n",
    "print(\"Number of unique values in yr_renovated: \",train['yr_renovated'].nunique())\n",
    "print(\"Number of unique values in waterfront: \",train['waterfront'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to pick a few categorical variables and see how that helps us improve our predictions. I will leave the exploration of the categorical variables to the reader. We must always keep in mind that the total number of features must not exceed the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring back our basement feature\n",
    "def to_categorical(row):\n",
    "    if row > 0:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['sqft_basement_cat'] = df['sqft_basement'].apply(to_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sqft_basement_cat')['id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of homes across zipcodes. We want to make sure that the homes are well spread across zipcodes to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['zipcode'])['id'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['bedrooms', 'sqft_living', 'view']\n",
    "categorical_features = ['waterfront', 'sqft_basement_cat', 'zipcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Hot Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap: One hot encoding is a representation of categorical variables in a way that is conducive to learning by algorithms. In one hot encoding, a categorical variable is reprsented as binary vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_list = []\n",
    "for column in categorical_features:\n",
    "    dfDummies = pd.get_dummies(df[column], prefix = column)\n",
    "    cat_features_list = cat_features_list + dfDummies.columns.tolist()\n",
    "    df = pd.concat([df, dfDummies], axis=1)\n",
    "    del df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[msk]\n",
    "test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = numeric_features+cat_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[all_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.array(train[all_features])\n",
    "target_train = np.array(train['price'])\n",
    "\n",
    "data_test = np.array(test[all_features])\n",
    "target_test = np.array(test['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=LinearRegression()\n",
    "model1.fit(data_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error: %.2f\" % mean_squared_error(target_test, preds))\n",
    "print(\"Root Mean Squared Error: %.2f\" % np.sqrt(mean_squared_error(target_test, preds)))\n",
    "print('R^2: %.2f' % r2_score(target_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and what you can explore on your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things to explore on your own:**\n",
    "- interaction variables \n",
    "    - we tried $y \\sim a_1 x_1 + c$ and $y ~ a_1 x_1 + a_2 x_2 +.... + a_n x_n$\n",
    "    - try exploring $y \\sim a_1 x_1 + a_2 x_2 + a_3 x_1 x_2$\n",
    "- regularization\n",
    "    - recap: in high dimensional data, you want to _regularize_ or shrink the coefficients of predictors to zero when you want a fit a model with all predictors in order to reduce variance\n",
    "     - [ridge regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "     - [lasso regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "- other algorithms like [decision trees](https://scikit-learn.org/stable/modules/tree.html), [random forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- different categorical varaibles\n",
    "- understand bias variance trade off\n",
    "- [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "    - recap: in the absence of designated test set, how to estimate test error?\n",
    "\n",
    "**Beware of:**\n",
    "- Highly correlated variables\n",
    "- Feature importance\n",
    "- exploding features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, this tutorial is not meant to be a recipe that one can blindly follow. If it was, there would have never been a need for a Data Scientist :-) This tutorial was only to give a basic overview of linear regression and how to implement that using standard libraries. More importantly, I hope you now have an idea of what sort of questions one should ask while creating a mathematical model. We hope that this has piqued your interest to explore the capabilities of machine learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
